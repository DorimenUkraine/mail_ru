{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В изысканиях опирался на данную статью: https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe\n",
    "Предварительно прослушал про ALS https://www.youtube.com/watch?v=NlNLtPqlCK0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train_2.csv')\n",
    "test = pd.read_csv('input/test_2.csv')\n",
    "user_features = pd.read_csv('input/user-features_2.csv')\n",
    "item_features = pd.read_csv('input/item-features_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = train.merge(user_features, how='left', left_on='user_id', right_on='user_id')\n",
    "train_full = train_full.merge(item_features, how='left', left_on='item_id', right_on='item_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime trains\n",
    "\n",
    "train_full['created'] = pd.to_datetime(train_full['timestamp'],unit='s')\n",
    "\n",
    "# create new date features\n",
    "\n",
    "train_full['created_month'] = train_full['created'].dt.month\n",
    "train_full['created_day'] = train_full['created'].dt.day\n",
    "train_full['created_dayofweek'] = train_full['created'].dt.dayofweek\n",
    "train_full['created_hour'] = train_full['created'].dt.round('H').dt.hour\n",
    "\n",
    "def f(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x <= 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x > 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Eve'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "    \n",
    "    \n",
    "train_full['part_of_day'] = train_full['created_hour'].apply(f)\n",
    "\n",
    "# train_full = train_full.drop(['created', 'timestamp'], axis=1)\n",
    "\n",
    "# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n",
    "train_full = pd.get_dummies(train_full, columns=[ 'part_of_day',], dummy_na=True)\n",
    "\n",
    "# удалю окончательно колонку даты и времени нажатия на баннер\n",
    "train_full = train_full.drop(['created'], axis = 1)\n",
    "\n",
    "if train_full.part_of_day_nan.isnull().sum() == 0:\n",
    "    train_full = train_full.drop(['part_of_day_nan'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime test\n",
    "\n",
    "test['created'] = pd.to_datetime(test['timestamp'],unit='s')\n",
    "\n",
    "# create new date features\n",
    "\n",
    "test['created_month'] = test['created'].dt.month\n",
    "test['created_day'] = test['created'].dt.day\n",
    "test['created_dayofweek'] = test['created'].dt.dayofweek\n",
    "test['created_hour'] = test['created'].dt.round('H').dt.hour\n",
    "\n",
    "def f(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x <= 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x > 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Eve'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "    \n",
    "    \n",
    "test['part_of_day'] = test['created_hour'].apply(f)\n",
    "\n",
    "# train_full = train_full.drop(['created', 'timestamp'], axis=1)\n",
    "\n",
    "# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n",
    "test = pd.get_dummies(test, columns=[ 'part_of_day',], dummy_na=True)\n",
    "\n",
    "# удалю окончательно колонку даты и времени нажатия на баннер\n",
    "test = test.drop(['created'], axis = 1)\n",
    "\n",
    "if test.part_of_day_nan.isnull().sum() == 0:\n",
    "    test = test.drop(['part_of_day_nan'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 444)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banner_pivot=train_full.pivot(index='user_id',columns='item_id',values='like')\n",
    "banner_pivot=banner_pivot.fillna(0)\n",
    "banner_pivot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497 entries, 0 to 496\n",
      "Columns: 444 entries, 0 to 443\n",
      "dtypes: float64(444)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "sparse_matrix = train_full.pivot(index='user_id',columns='item_id',values='like')\n",
    "sparse_matrix = sparse_matrix.fillna(0)\n",
    "sparse_matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csr_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ac9a28b90d3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msparse_matrix_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msparse_matrix_sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csr_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# sparse_matrix_sparse = csr_matrix(sparse_matrix.values)\n",
    "# sparse_matrix_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matricies, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "sparse_item_user = sparse.csr_matrix((train_full['like'].astype(float), (train_full['item_id'], train_full['user_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((train_full['like'].astype(float), (train_full['user_id'], train_full['item_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<497x444 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8674 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa9b646bce247f79090f5753bcddff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors=3, regularization=0.01, iterations=40)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(data_conf)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Similar Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "304\n",
      "382\n",
      "292\n",
      "287\n",
      "308\n",
      "290\n",
      "286\n",
      "396\n",
      "330\n",
      "406\n",
      "393\n",
      "440\n",
      "428\n",
      "441\n",
      "379\n",
      "288\n",
      "327\n",
      "244\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "#---------------------\n",
    "# FIND SIMILAR ITEMS\n",
    "#---------------------\n",
    "\n",
    "# Find the 10 most similar\n",
    "item_id = 400\n",
    "n_similar = 20\n",
    "\n",
    "# Use implicit to get similar items.\n",
    "similar = model.similar_items(item_id, n_similar)\n",
    "\n",
    "# Print the names of our most similar artists\n",
    "for item in similar:\n",
    "    idx, score = item\n",
    "    print(train_full.item_id.loc[train_full.item_id == idx].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1    2   3   4   5    6    7    8    9   10   11   12  13   14   15  \\\n",
      "166  22  35   37  72  80  65   17  136   19  155   58   70   40  34  147   88   \n",
      "26   21  87  101  49  84  30    2   19    7   26    4  129   90  39  104   18   \n",
      "41   76  87    5  21  39  18   90   62   45   33  101   66   84  75    9   44   \n",
      "286  72  35   22  80  78  65  172  147   11   58   60   76  119  66  146   71   \n",
      "108  22  35   72  37  80  67   40  147  136   58   17  155   70  60   34   78   \n",
      "..   ..  ..  ...  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ..  ...  ...   \n",
      "190  76  66   35  60  32  33   65  146    5   36   37   70  119  59   21   71   \n",
      "181   7  21   39  18  90   5   76  101   62    2   45   33   75  30    4    6   \n",
      "448  76  66   58  60  72  35   32   36   65  147   33   70   63  22  118  159   \n",
      "124  22  35   72  80  65  67   40  147   58  136   17  155   70  78   34   88   \n",
      "167  58  22   33  80  37  66   21   60   40   87   88    5  146  78   11   59   \n",
      "\n",
      "      16   17   18   19  \n",
      "166  113   60   30  141  \n",
      "26    27   73   99   53  \n",
      "41   114    6    2  180  \n",
      "286   70   44   37   77  \n",
      "108  113   88  184   77  \n",
      "..   ...  ...  ...  ...  \n",
      "190   87  147   43  137  \n",
      "181   49   99  114   83  \n",
      "448  142   77  155    9  \n",
      "124   32   36  113   77  \n",
      "167  118   43   41   18  \n",
      "\n",
      "[497 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "#------------------------------\n",
    "# CREATE USER RECOMMENDATIONS\n",
    "#------------------------------\n",
    "\n",
    "recommendations = {}\n",
    "\n",
    "# Create recommendations for user\n",
    "for u in test['user_id']:\n",
    "# for u in range(2):\n",
    "    \n",
    "    user_id = u\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    recommended = model.recommend(user_id, sparse_user_item, 20)\n",
    "\n",
    "    item_id = []\n",
    "    scores = []\n",
    "\n",
    "    # Get artist names from ids\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        item_id.append(train_full.item_id.loc[train_full.item_id == idx].iloc[0])\n",
    "        scores.append(score)\n",
    "\n",
    "    # Create a dataframe of artist names and scores\n",
    "    # recommendations = pd.DataFrame({'user_id': user_id, 'item_id': item_id, 'score': scores})\n",
    "    recommendations.update({user_id: item_id})\n",
    "\n",
    "\n",
    "rec_df = pd.DataFrame.from_dict(recommendations)\n",
    "    \n",
    "print(rec_df.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Экспорт предсказаний в csv\n",
    "pd.DataFrame(rec_df.T).to_csv('input/out.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
